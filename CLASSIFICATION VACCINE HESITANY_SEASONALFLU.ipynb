{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Flu Vaccine Hesitancy: A Machine Learning Approach for Informed Public Health Intervention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "[1. INTRODUCTION](#1.INTRODUCTION) </br>\n",
    "[1.1 BUSINESS UNDERSTANDING](#1.1BUSINESS-UNDERSTANDING) </br>\n",
    "[1.2 Problem Statement](#1.2Problem-Statement) </br>\n",
    "[1.3 Objectives](#1.3Objectives) </br>\n",
    "[1.3.1 Main Objective](#1.3.1Main-Objective) </br>\n",
    "[1.3.2 Specific Objective](#1.3.2Specific-Objectives) </br>\n",
    "[2. Libraries](#2.LOADING-LIBRARIES) </br>\n",
    "[3. Data Understanding](#3.Data-Understanding) </br>\n",
    "[4. Data Cleaning](#4.Data-Cleaning) </br>\n",
    "[4.1 Dropping irrelevant-columns](#4.1Dropping-irrelevant-columns) </br>\n",
    "[4.2 Checking for-duplicates](#4.2Checking-for-duplicates) </br>\n",
    "[4.3 Checking for any placeholders](#4.3Checking-for-any-placeholders) </br>\n",
    "[4.4 Checking for missing values](#4.4Checking-for-missing-values) </br>\n",
    "[5. EXPLORATION DATA ANALYSIS](#5.EXPLORATION-DATA-ANALYSIS) </br>\n",
    "[5.1 Univariate Analysis](#5.1Univariate-Analysis) </br>\n",
    "[5.2 Bivariate analysis](#5.2Bivariate-analysis) </br>\n",
    "[6. Feature Engineering](#6.Feature-Engineering) </br>\n",
    "[7. Data Modelling](#7.Data-Modelling) </br>\n",
    "[7.1 Logistic Regression](#7.1Logistic-Regression) </br>\n",
    "[7.2 Decision Tree](#7.2Decision-Tree) </br>\n",
    "[7.2.1 Tree Pruning](#7.2.1Tree-Pruning) </br>\n",
    "[7.3 KNN](#7.3KNN) </br>\n",
    "[7.4 Naive Bayes](#7.4Naive-Bayes) </br>\n",
    "[7.5 Ensemble methods](#7.5Ensemble-methods) </br>\n",
    "[7.5.1 Random Forest](#7.5.1Random-Forest) </br>\n",
    "[7.3.2 XGBoost](#7.3.2XGBoost) </br>\n",
    "[8. Data Evaluation](#8.Data-Evaluation) </br>\n",
    "[9. Conclusion](#9.Conclusion) </br>\n",
    "[10. Recommendations](#10.Recommendations) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is aimed to provide insights into predicting seasonal flu vaccination status accurately and identifying key factors influencing vaccination decisions. The results from this study could contribute to optimizing pro-vaccination efforts and targeting specific subgroups to maximize the benefits of herd immunity, particularly in the context of seasonal flu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1BUSINESS UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to address the following inquiries to enhance our comprehension of the structure surrounding seasonal flu vaccination:\n",
    "\n",
    "- What are the determinants that impact an individual's decision to opt for the seasonal flu vaccine?\n",
    "- Among different population segments, which should be the focal point of pro-vaccine campaigns aimed at augmenting the overall annual vaccination uptake?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaccination has greatly improved public health, yet vaccine skepticism is causing immunization rates to decline. This trend prompted research into vaccination attitudes.\n",
    "\n",
    "Amid this, flu vaccine hesitancy is a major concern, hindering efforts against seasonal flu outbreaks. Despite the flu causing millions of hospitalizations and 52,000 deaths annually, only 51.4% received the vaccine in the 2021-22 season. Hesitancy leads to disease spread, strains healthcare, and may cause co-infections, causing economic burdens and disrupting daily life.\n",
    "\n",
    "Prompt flu vaccination is crucial, especially during fall and winter when flu and COVID-19 can spread together. It reduces co-infection risk and eases healthcare strain.\n",
    "\n",
    "Flu vaccine hesitancy is driven by factors like misinformation, safety fears, beliefs, and access. Understanding these helps design effective interventions.\n",
    "\n",
    "The Ministry of Health assigned us to address flu vaccine hesitancy. Our study uses machine learning to predict flu vaccine likelihood. By analyzing data, we empower experts to understand low vaccination rates and overcome barriers. This bridges the gap between hesitancy and effective interventions, creating a healthier community\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3Objectives\n",
    "### 1.3.1Main Objective\n",
    "* To utilize machine learning to understand flu vaccine hesitancy by predicting the likelihood of individuals receiving their seasonal flu vaccines\n",
    "\n",
    "### 1.3.2Specific Objectives\n",
    "* To identify socio-cultural, psychological, and communication-related factors that factors that affect flu vaccine hesitancy.\n",
    "* To develop a classifier model for vaccine hesitancy based on historical data\n",
    "* To develop data informed recommendations to increase flu vaccine uptake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.LOADING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFE\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report,\\\n",
    "confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score, auc, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier,\\\n",
    "GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The data used were obtained from(<a href=\"https://www.drivendata.org/competitions/66/flu-shot-learning/page/211/#labels\"> Here</a>). and contains 36 columns. \n",
    "\n",
    "The first column respondent_id is a unique and random identifier. The remaining 35 features are described below.For all binary variables: 0 = No; 1 = Yes.\n",
    "\n",
    "- `h1n1_concern `- Level of concern about the H1N1 flu.\n",
    "\n",
    "    0 = Not at all concerned; 1 = Not very concerned; 2 = Somewhat concerned; 3 = Very concerned.\n",
    "\n",
    "- `h1n1_knowledge `- Level of knowledge about H1N1 flu.\n",
    "\n",
    "    0 = No knowledge; 1 = A little knowledge; 2 = A lot of knowledge.\n",
    "\n",
    "- `behavioral_antiviral_meds` - Has taken antiviral medications. (binary)\n",
    "- `behavioral_avoidance `- Has avoided close contact with others with flu-like symptoms. (binary)\n",
    "- `behavioral_face_mask `- Has bought a face mask. (binary)\n",
    "- `behavioral_wash_hands` - Has frequently washed hands or used hand sanitizer. (binary)\n",
    "- `behavioral_large_gatherings `- Has reduced time at large gatherings. (binary)\n",
    "- `behavioral_outside_home `- Has reduced contact with people outside of own household. (binary)\n",
    "- `behavioral_touch_face `- Has avoided touching eyes, nose, or mouth. (binary)\n",
    "- `doctor_recc_h1n1 `- H1N1 flu vaccine was recommended by doctor. (binary)\n",
    "- `doctor_recc_seasonal `- Seasonal flu vaccine was recommended by doctor. (binary)\n",
    "- `chronic_med_condition `- Has any of the following chronic medical conditions: asthma or an other lung condition, diabetes, a heart condition, a kidney condition, sickle cell anemia or other anemia, a neurological or neuromuscular condition, a liver condition, or a weakened immune system caused by a chronic illness or by medicines taken for a chronic illness. (binary)\n",
    "- `child_under_6_months` - Has regular close contact with a child under the age of six months. (binary)\n",
    "- `health_worker` - Is a healthcare worker. (binary)\n",
    "- `health_insurance `- Has health insurance. (binary)\n",
    "- `opinion_h1n1_vacc_effective` - Respondent's opinion about H1N1 vaccine effectiveness.\n",
    "1 = Not at all effective; 2 = Not very effective; 3 = Don't know; 4 = Somewhat effective; 5 = Very effective.\n",
    "opinion_h1n1_risk - Respondent's opinion about risk of getting sick with H1N1 flu without vaccine.\n",
    "1 = Very Low; 2 = Somewhat low; 3 = Don't know; 4 = Somewhat high; 5 = Very high.\n",
    "- `opinion_h1n1_sick_from_vacc` - Respondent's worry of getting sick from taking H1N1 vaccine.1 = Not at all worried; 2 = Not very worried; 3 = Don't know; 4 = Somewhat worried; 5 = Very worried.\n",
    "- `opinion_seas_vacc_effective` - Respondent's opinion about seasonal flu vaccine effectiveness.\n",
    "1 = Not at all effective; 2 = Not very effective; 3 = Don't know; 4 = Somewhat effective; 5 = Very effective.\n",
    "opinion_seas_risk - Respondent's opinion about risk of getting sick with seasonal flu without vaccine.\n",
    "1 = Very Low; 2 = Somewhat low; 3 = Don't know; 4 = Somewhat high; 5 = Very high.\n",
    "- `opinion_seas_sick_from_vacc `- Respondent's worry of getting sick from taking seasonal flu vaccine.\n",
    "1 = Not at all worried; 2 = Not very worried; 3 = Don't know; 4 = Somewhat worried; 5 = Very worried.\n",
    "\n",
    "- `age_group `- Age group of respondent.\n",
    "- `education `- Self-reported education level.\n",
    "- `race` - Race of respondent.\n",
    "- `sex `- Sex of respondent.\n",
    "- `income_poverty `- Household annual income of respondent with respect to 2008 Census poverty thresholds.\n",
    "- `marital_status `- Marital status of respondent.\n",
    "- `rent_or_own` - Housing situation of respondent.\n",
    "- `employment_status `- Employment status of respondent.\n",
    "- `hhs_geo_region `- Respondent's residence using a 10-region geographic classification defined by the U.S. Dept. of Health and Human Services. Values are represented as short random character strings.\n",
    "- `census_msa `- Respondent's residence within metropolitan statistical areas (MSA) as defined by the U.S. Census.\n",
    "household_adults - Number of other adults in household, top-coded to 3.\n",
    "- `household_children` - Number of children in household, top-coded to 3.\n",
    "- `employment_industry` - Type of industry respondent is employed in. Values are represented as short random character strings.\n",
    "- `employment_occupation` - Type of occupation of respondent. Values are represented as short random character strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 3 fields in line 26711, saw 36\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Importing file with the corresponding target variable\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m display(features\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      8\u001b[0m labels\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 3 fields in line 26711, saw 36\n"
     ]
    }
   ],
   "source": [
    "# Importing data \n",
    "# Importing  file containing  features \n",
    "features = pd.read_csv('features.csv')\n",
    "\n",
    "# Importing file with the corresponding target variable\n",
    "labels = pd.read_csv('labels.csv')\n",
    "display(features.head())\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the features and labels into a single DataFrame for cleaning and exploration\n",
    "df = pd.concat([features, labels.drop('respondent_id', axis=1)], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shape of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables `hhs_geo_region`, `employment_industry`, and `employment_occupation` are encoded as random strings and correspond to specific geographic regions, industries, and occupations. The CDC has not provided the meanings of these strings to protect the anonymity of respondents. Nonetheless, our model can utilize this information to enhance prediction accuracy. Including these variables in our analysis will allow us to determine their relevance in predicting an individual's likelihood of obtaining a vaccine, even if we cannot establish a direct connection to specific regions or jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  The rows represent unique respondent's view \n",
    "* Each column represents respondentâ€™s details in relation to seasonal flu vaccine\n",
    "* The target column is `seasonal_vaccine`. The variable is binary coded as 0 = No; 1 = Yes and denotes if respondent received seasonal flu vaccine.\n",
    "* For all binary variables: 0 = No; 1 = Yes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Data Cleaning\n",
    "This entails dropping irrelevant columns,  identifying and rectifying errors, inconsistencies, and inaccuracies to enhance data quality and reliability.\n",
    "\n",
    "The data was checked for:\n",
    "* Missing values\n",
    "* Outliers\n",
    "* Inconsistencies\n",
    "* Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1Dropping irrelevant columns\n",
    "\n",
    "* The project focuces on seasonal flu vaccine. As such all columns related with information on H1N1 were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns with information on H1N1\n",
    "df.drop(columns=['opinion_h1n1_vacc_effective',\n",
    "                 'opinion_h1n1_risk',\n",
    "                 'opinion_h1n1_sick_from_vacc',\n",
    "                 'doctor_recc_h1n1','h1n1_concern',\n",
    "                 'h1n1_knowledge','h1n1_vaccine'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "# Print the duplicate rows\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The data does not have duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for id duplicates. \n",
    "##### Each respondent id is unique and there should be no duplicated ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for duplicates\n",
    "id_duplicates = df[df.duplicated(subset=['respondent_id'], keep=False)]\n",
    "id_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The were no duplicate `respodent_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3Checking for any placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    placeholders = [value for value in unique_values if str(value).strip().lower() in ['placeholder', 'na', 'n/a', 'none']]\n",
    "    placeholder_count = len(placeholders)    \n",
    "    unique_value_counts = df[column].value_counts()    \n",
    "    print(f\"Column: '{column}'\")\n",
    "    print(f\"Unique value counts:\")\n",
    "    print(unique_value_counts)\n",
    "    print()\n",
    "    print(f\"Placeholders:\")\n",
    "    print(placeholders)\n",
    "    print(f\"Count of placeholders: {placeholder_count}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* some columns have `NaN`  placeholders. below is  code to show the proportion per each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in each column and calculate their sum\n",
    "nan_sum_per_column = df.isna().sum()\n",
    "print(\"NaN Sum per Column:\")\n",
    "print(nan_sum_per_column)\n",
    "total_nan_sum = nan_sum_per_column.sum()\n",
    "print(\"\\nTotal NaN Sum:\", total_nan_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a Pandas DataFrame displaying the number of null values for \n",
    "# each column in the original DataFrame, \n",
    "# as well as the total percent of each column that is made up of null values. \n",
    "def check_null(df):\n",
    "    missing_vals = pd.DataFrame()\n",
    "    missing_vals['Number of Nulls'] = df.isna().sum()\n",
    "    missing_vals['% Null'] = (df.isna().sum() / len(df)) * 100\n",
    "    \n",
    "    missing_vals = missing_vals.sort_values(by='Number of Nulls')\n",
    "    \n",
    "    return missing_vals\n",
    "\n",
    "check_null(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the complete dataset contains a significant number of observations (26,707), and most columns have only a small proportion of missing values, any record with missing information in columns containing less than 5% missing values will be excluded.\n",
    "\n",
    " - `behavioral_antiviral_meds`\n",
    " - `behavioral_avoidance`\n",
    " - `behavioral_face_mask` \n",
    " - `behavioral_wash_hands`\n",
    " - `behavioral_large_gatherings` \n",
    " - `behavioral_outside_home`\n",
    " - `behavioral_touch_face` \n",
    " - `chronic_med_condition`\n",
    " - `child_under_6_months` \n",
    " - `health_worker` \n",
    " - `opinion_seas_vacc_effective`\n",
    " - `opinion_seas_risk` \n",
    " - `opinion_seas_sick_from_vacc` \n",
    " - `household_adults`\n",
    " - `household_children`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a visualization to understand missing values \n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.isnull(), cmap='viridis', cbar=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1Dealing with missing values in `employment_status` and `employment_occupation`\n",
    " * The columns employment_occupation, employment_industry, and health_insurance have the most missing values, at 50.4%, 49.9%, and 46.0% respectively. However, it is important to note that some of these missing values are not due to respondents declining to answer, but rather because they are not applicable. For example, 10,231 respondents who are classified as 'Not in Labor Force' have missing values for employment_occupation and employment_industry. Similarly, 1,453 unemployed respondents have missing values for these columns. In these cases, it is more appropriate to consider employment_occupation and employment_industry as 'not applicable' rather than missing values.\n",
    "\n",
    "* There are also evident patterns in missing values. For example, respondents who declined to answer about one aspect, such as whether their doctor recommended a specific vaccine, often did the same for other related questions. This trend was also observed for questions regarding chronic medical conditions, having a child under 6 months, being a health worker, opinion questions, income, education, personal and home life questions.\n",
    "\n",
    "* These patterns suggest that treating missing information for certain variables as a distinct category rather than dropping it altogether may be more meaningful. This is because it appears to represent a specific type of respondent that constitutes a noteworthy portion of the sample population\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice out DataFrame for individuals Not in Labor Force\n",
    "not_in_labor_force = df[df['employment_status']=='Not in Labor Force']\n",
    "\n",
    "# display the number and percent of NaN's in each column\n",
    "display(check_null(not_in_labor_force))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # slice out DataFrame for 'Unemployed' individuals\n",
    "unemployed = df[df['employment_status']=='Unemployed']\n",
    "\n",
    "# # display the number and percent of NaN's in each column\n",
    "check_null(unemployed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_lab_for_ids = list(not_in_labor_force['respondent_id'].index)\n",
    "unempl_ids = list(unemployed['respondent_id'].index)\n",
    "all_not_employed_ids = not_lab_for_ids + unempl_ids\n",
    "len(all_not_employed_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function to slice and isolate labor force related data\"\"\"\n",
    "# The function accepts a Pandas DataFrame along with a designated column name, \n",
    "# and returns a new Pandas DataFrame presenting distinct values within that column, \n",
    "# accompanied by their respective occurrence counts. By default, the function also includes a tally of NaN values.\n",
    "def check_unique(df, col, dropna=False):\n",
    "    unique_vals = pd.DataFrame(df[col].value_counts(dropna=dropna))\n",
    "    \n",
    "    return unique_vals\n",
    "       \n",
    "for col in df.columns:\n",
    "    display(check_unique(df, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a person is unemployed, change their 'employment_occupation' to 'not_employed'\n",
    "df.loc[df['employment_status'] == 'Unemployed', 'employment_occupation'] = 'not employed'\n",
    "\n",
    "# if a person is not in the labor force, change their 'employment_occupation' to 'not_employed'\n",
    "df.loc[df['employment_status'] == 'Not in Labor Force', 'employment_occupation'] = 'not employed'\n",
    "check_unique(df, 'employment_occupation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping records if they are missing information in any column comprised of less than 5% missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame to show columns with % Null between 0 and 5%\n",
    "null_df = check_null(df)\n",
    "null_df.drop(index=null_df.loc[null_df['% Null']==0].index, axis=0, inplace=True)\n",
    "under_5_null = null_df.loc[null_df['% Null']<5]\n",
    "under_5_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop records with null values for the above columns, composed of less than 5% null values\n",
    "under_5_null_cols = list(under_5_null.index)\n",
    "df.dropna(subset=under_5_null_cols, inplace=True)\n",
    "\n",
    "# check out the resulting df\n",
    "display(check_null(df))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The column `respondent_id` will not be used hence dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['respondent_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is a good representation of the general population in terms of vaccination status and gender. However, there is a significant underrepresentation of people of color, and a high percentage of respondents who declined to answer the health insurance question. This is important to keep in mind when interpreting the results of any analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.EXPLORATION DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Separate the columns into numeirical and categorical \n",
    "numeric_columns = data.select_dtypes(include=['number']).columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  5.1.1 Bar Chart for all numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" function to create bar charts for numerical columns \"\"\"\n",
    "def create_bar_charts(data):\n",
    "    numeric_columns = data.select_dtypes(include=['number']).columns\n",
    "    num_columns = len(numeric_columns)\n",
    "    rows = (num_columns + 1) // 2  # Calculate the number of rows needed (2 columns per row)\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, 2, figsize=(15, 6 * rows))\n",
    "    \n",
    "    for i, column in enumerate(numeric_columns):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        data[column].value_counts().plot(kind='bar', color=['green', 'orange'], ax=axes[row, col])\n",
    "        axes[row, col].set_title(f'{column} Distribution')\n",
    "        axes[row, col].set_xlabel(column)\n",
    "        axes[row, col].set_ylabel('Count')\n",
    "        axes[row, col].tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "create_bar_charts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* behavioral_antiviral_meds: Most respondents have not taken antiviral medications as a preventive measure.\n",
    "* behavioral_avoidance: Majority of respondents have practiced behavioral avoidance to prevent illness.\n",
    "* behavioral_face_mask: Most respondents have not consistently used face masks as a preventive measure.\n",
    "* behavioral_wash_hands: Most respondents have practiced frequent handwashing to prevent illness.\n",
    "* behavioral_large_gatherings: A significant number of respondents have avoided large gatherings to reduce exposure.\n",
    "* behavioral_outside_home: Many respondents have minimized going outside their homes.\n",
    "* behavioral_touch_face: Majority of respondents have been conscious about avoiding touching their faces.\n",
    "* doctor_recc_seasonal: A considerable number of respondents received a doctor's recommendation for seasonal    vaccination.\n",
    "* chronic_med_condition: A significant portion of respondents reported having a chronic medical condition.\n",
    "* child_under_6_months: Many respondents do not have children under 6 months of age.\n",
    "* health_worker: A notable number of respondents are health workers.\n",
    "* health_insurance: A majority of respondents have health insurance coverage.\n",
    "* opinion_seas_vacc_effective: Many respondents hold a positive opinion about the effectiveness of seasonal vaccines.\n",
    "* opinion_seas_risk: Respondents have varying opinions about the risk of seasonal vaccination.\n",
    "* opinion_seas_sick_from_vacc: Opinions about getting sick from vaccines are varied among respondents.\n",
    "* household_adults: Many households have 1 or more adults, with a significant number having only 1 adult.\n",
    "* household_children: Households vary in the number of children, with a substantial number having no children.\n",
    "* seasonal_vaccine: The number of respondents who received the seasonal vaccine is somewhat close to those who did not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.2 Plotting bar charts for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" function to create bar charts for categorical columns \"\"\"\n",
    "#Plotting categorical data\n",
    "categorical_columns = ['age_group', 'education', 'sex', 'income_poverty', 'marital_status',\n",
    "                       'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa', 'race',\n",
    "                       'doctor_recc_seasonal', 'health_insurance']\n",
    "\n",
    "def create_bar_charts(data):\n",
    "    num_columns = len(categorical_columns)\n",
    "    rows = (num_columns + 1) // 2  # Calculate the number of rows needed (2 columns per row)\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, 2, figsize=(15, 6 * rows))\n",
    "    \n",
    "    for i, column in enumerate(categorical_columns):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        data[column].value_counts().plot(kind='bar', color=['blue', 'orange'], ax=axes[row, col])\n",
    "        axes[row, col].set_title(f'{column} Distribution')\n",
    "        axes[row, col].set_xlabel(column)\n",
    "        axes[row, col].set_ylabel('Count')\n",
    "        axes[row, col].tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "create_bar_charts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Age Group: The population is predominantly older, with the 65+ years and 55-64 years age groups having the highest counts.\n",
    "* Education: The majority of individuals have attained at least a college education, with a notable number having completed some college.\n",
    "* Sex: Females are more than males\n",
    "* Income Poverty: A significant proportion of individuals have an income above poverty, with many falling within the <= $75,000, Above Poverty category.\n",
    "* Marital Status: A fairly even distribution between married and not married individuals.\n",
    "* Rent or Own: More individuals own their residences than rent.\n",
    "* Employment Status: A large portion of the population is employed, while a smaller number are not in the labor force or are unemployed.\n",
    "* HHS Geo Region: Individuals are distributed across different Health and Human Services geographical regions.\n",
    "* Census MSA: Individuals are spread across various Metropolitan Statistical Area categories.\n",
    "* Race: The dataset is predominantly composed of White individuals, with smaller representations of Black, Hispanic, and Other/Multiple racial backgrounds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2Bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  5.2.1 Bivariate bar charts for numerical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" function to create bar charts for numerical columns \"\"\"\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "for column in numeric_columns:\n",
    "    # Count the occurrences of each unique value in the numeric column\n",
    "    grouped_data_0 = df[df['seasonal_vaccine'] == 0][column].value_counts()\n",
    "    grouped_data_1 = df[df['seasonal_vaccine'] == 1][column].value_counts()\n",
    "\n",
    "    # Get the unique values in the numeric column\n",
    "    unique_values = sorted(df[column].unique())\n",
    "\n",
    "    # Create a DataFrame with the counts of each unique value for both classes\n",
    "    stacked_data = pd.DataFrame({\n",
    "        'Value': unique_values,\n",
    "        'Not Vaccinated': [grouped_data_0.get(val, 0) for val in unique_values],\n",
    "        'Vaccinated': [grouped_data_1.get(val, 0) for val in unique_values]\n",
    "    })\n",
    "\n",
    "    # Create a stacked bar chart\n",
    "    stacked_data.set_index('Value').plot(kind='bar', stacked=True)\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Stacked Bar Chart: ' + column + ' Count by Seasonal Vaccine')\n",
    "\n",
    "    # Show the legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* behavioral_antiviral_meds: Those with antiviral meds taken are more vaccinated than those with antiviral meds not taken.\n",
    "* behavioral_avoidance: Those practicing avoidance behaviors are more vaccinated than those not practicing avoidance behaviors.\n",
    "* behavioral_face_mask: Those wearing face masks are more vaccinated than those not wearing face masks.\n",
    "* behavioral_wash_hands: Those practicing handwashing are more vaccinated than those not practicing handwashing.\n",
    "* behavioral_large_gatherings: Those not practicing avoidance of large gatherings are more vaccinated than those practicing avoidance.\n",
    "* behavioral_outside_home: Those going outside home are more vaccinated than those not going outside home.\n",
    "* behavioral_touch_face: Those avoiding touching face are more vaccinated than those not avoiding.\n",
    "* doctor_recc_seasonal: Those with a doctor recommendation for seasonal vaccination are more vaccinated than those without a recommendation.\n",
    "* chronic_med_condition: Those without chronic medical conditions are more vaccinated than those with chronic conditions.\n",
    "* child_under_6_months: Those without a child under 6 months are more vaccinated than those with a child.\n",
    "* health_worker: Health workers are more vaccinated than non-health workers.\n",
    "* health_insurance: Those with health insurance are more vaccinated than those without.\n",
    "* opinion_seas_vacc_effective: Those who find the seasonal vaccine very effective are more vaccinated than those who find it somewhat effective.\n",
    "* opinion_seas_risk: Those perceiving a moderate risk from the vaccine are more vaccinated than those perceiving somewhat low risk.\n",
    "* opinion_seas_sick_from_vacc: Those not worried about getting sick from the vaccine are more vaccinated than those somewhat worried.\n",
    "* household_adults: Those with one adult in the household are more vaccinated than those with zero adults.\n",
    "* household_children: Those without children in the household are more vaccinated than those with three children.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.2 Bivariate bar charts for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" function to create bar charts for categorical columns \"\"\"\n",
    "\n",
    "# Define a set of three colors for the bars\n",
    "colors = ['blue', 'orange', 'green']\n",
    "\n",
    "# Loop through each categorical column and create bar charts\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    # Calculate the count 'seasonal_vaccine' for each category\n",
    "    grouped_data = df.groupby(column)['seasonal_vaccine'].value_counts()\n",
    "\n",
    "    # Sort the index of grouped_data by the counts in descending order\n",
    "    grouped_data = grouped_data.sort_values(ascending=False)\n",
    "\n",
    "    # Create a bar chart\n",
    "    plt.figure(figsize=(8, 6))  \n",
    "    grouped_data.plot(kind='bar', alpha=0.7, color=colors[i % len(colors)])  \n",
    "\n",
    "    # Set labels and title\n",
    "    plt.title(f'Bar Chart: Count Seasonal Vaccine by {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Count Seasonal Vaccine')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* age_group: Most vaccinated is 18 - 34 while least vaccinated is 65+.\n",
    "* education: Most vaccinated is college graduate while least vaccinated is < 12 Years.\n",
    "* sex: Most vaccinated is female \n",
    "* income_poverty: Most vaccinated is > $75,000 while least vaccinated is <= $75,000, above poverty.\n",
    "* marital_status: Most vaccinated is married while least vaccinated is not married.\n",
    "* rent_or_own: Most vaccinated is own while least vaccinated is rent.\n",
    "* employment_status: Most vaccinated is Employed while least vaccinated is not in labor force.\n",
    "* race: Most vaccinated is White while least vaccinated is Black.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Feature Engineering\n",
    "* In this section some columns were combined to create new columns  which are deemed more informative based on domain knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new variable  that represents an individual's behavioral efforts to avoid the flu, excluding vaccination. We will sum up all behavior related  columns, where a value of 1 indicates a behavior that reduces the risk of contracting the flu. A higher flu_avoidance_score will indicate a more careful and flu-conscious individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping all columns with behavioral characteristics\n",
    "behavior_cols = [col for col in df.columns if 'behavioral' in col]\n",
    "behavior_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a Df and specific column name and returns a Pandas DataFrame \n",
    "# displaying the unique values in that column as well as the count of each unique value. \n",
    "# Also displays a histogram (Seaborn distplot) showing the distribution of the column values.\n",
    "def check_col_distr(df, col):    \n",
    "    ## check counts of unique values in col\n",
    "    display(check_unique(df, col))\n",
    "     ## plot distribution of col\n",
    "    plt.figure(figsize=(7,5))\n",
    "    fig = sns.displot(df[col])\n",
    "    \n",
    "    return fig\n",
    "       \n",
    "df['behaviour_score'] = df[behavior_cols].sum(axis=1)\n",
    "check_col_distr(df, 'behaviour_score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable that represents the ratio of how much an individual has done behaviorally to avoid the flu (aside from getting vaccinated) to their perception of the risk of getting the flu without the vaccine.\n",
    "\n",
    "The numerator of the ratio is behav_score + 1, which ranges from 1 to 7. This is to differentiate among individuals who are not taking any action to avoid the flu, but differ in the degree to which they are concerned about getting sick without the vaccine. An individual with a score of 1 has done nothing to avoid the flu but is very concerned about getting sick without the vaccine. An individual with a score of 7 has done everything they can to avoid the flu and is not very concerned about getting sick without the vaccine.\n",
    "\n",
    "The denominator of the ratio is the rating of risk perception, opinion_seas_risk, which ranges from 1 to 5. This represents the individual's perception of the risk of getting the flu without the vaccine. An individual with a score of 1 believes that the risk of getting the flu without the vaccine is very low. An individual with a score of 5 believes that the risk of getting the flu without the vaccine is very high.\n",
    "\n",
    "The flu_avoidance_behavior_to_risk_ratio variable can be used to understand how an individual's behavioral risk avoidance and risk perception relate to their likelihood of getting the flu vaccine. An individual with a low flu_avoidance_behavior_to_risk_ratio is more likely to get the flu vaccine, as they are both concerned about getting sick and have not taken many steps to avoid the flu. An individual with a high flu_avoidance_behavior_to_risk_ratio is less likely to get the flu vaccine, as they are not very concerned about getting sick and have taken many steps to avoid the flu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['behaviour_to_risk'] = (df['behaviour_score'] + 1) / df['opinion_seas_risk']\n",
    "\n",
    "# check counts of unique values in new col and plot distribution\n",
    "check_col_distr(df, 'behaviour_to_risk');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a variable for whether or not an individual is 65 years or older as this represents a group at higher risk for serious complications from the flu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_older_65(row):\n",
    "    if row['age_group'] == '65+ Years':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# apply the function to create new column\n",
    "df['older_65'] = df.apply(lambda x: is_older_65(x), axis=1)\n",
    "\n",
    "##check counts of unique values in new col and plot distribution\n",
    "check_col_distr(df, 'older_65');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a variable to represent an individual's overall risk of developing flu-related complications. This risk is influenced by certain factors that make some individuals more susceptible to severe flu outcomes. Those at higher risk include:\n",
    "\n",
    "1. Individuals aged **65 years and older**.\n",
    "2. **Children 6 months or younger**, as well as people in close contact with a child under 6 months, since they share an increased risk.\n",
    "3. People with **chronic medical conditions**, such as asthma, other lung conditions, diabetes, heart conditions, kidney conditions, sickle cell anemia or other anemia, neurological or neuromuscular conditions, liver conditions, or weakened immune systems.\n",
    "\n",
    "The variable serves to acknowledge the heightened vulnerability of these groups to flu-related complications, providing valuable information for public health assessments and interventions.\n",
    "(<a href=\"https://www.cdc.gov/flu/highrisk/index.htm\"> CDC - \"People at High Risk for Flu Complications\"</a>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate score for high risk of complications\n",
    "def calc_high_risk(row):\n",
    "    risk = 0\n",
    "    if row['older_65'] == 1:\n",
    "        risk += 1\n",
    "    if row['child_under_6_months'] == 1:\n",
    "        risk += 1\n",
    "    if row['chronic_med_condition'] == 1:\n",
    "        risk += 1\n",
    "    return risk\n",
    "\n",
    "## apply the function to create new column\n",
    "df['high_risk_complications'] = df.apply(lambda x: calc_high_risk(x), axis=1)\n",
    "\n",
    "## check counts of unique values in new col and plot distribution\n",
    "check_col_distr(df, 'high_risk_complications');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a categorical variable that groups persons with numerous high risk characteristics ('high_risk_compl' > 1) into one 'high risk' category, assigning a value of 0 to 'low risk' and a value of 1 to'med risk'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['high_risk_category'] = df['high_risk_complications'].map({0:'low risk', 1:'med risk',\n",
    "                                                 2:'high risk', 3:'high risk'})\n",
    "\n",
    "## check counts of unique values in new col\n",
    "df['high_risk_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change binary variable from floats to strings without altering NaN values\n",
    "#(NaN will be automatically filled with 'missing' later)\n",
    "df['doctor_recc_seasonal'] = df['doctor_recc_seasonal'].map({1.0: '1', 0.0: '0'})\n",
    "df['doctor_recc_seasonal'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['health_insurance'] = df['health_insurance'].map({1.0: '1', 0.0: '0'})\n",
    "df['health_insurance'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since they're so underrepresented in the dataset, \n",
    " # we create a function to return make combine people of color into one category \n",
    "\n",
    "def race_func(row):\n",
    "    if row['race'] == 'White':\n",
    "        return 'White'\n",
    "    else:\n",
    "        return 'POC'\n",
    "\n",
    "# apply the function to create new column\n",
    "df['race'] = df.apply(lambda x: race_func(x), axis=1)\n",
    "\n",
    "# check counts of unique values in new col and plot distribution\n",
    "df['race'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # A list of intermediate engineered features that will be highly correlated\n",
    "# with other features\n",
    "feats_to_drop = ['older_65', 'high_risk_complicationa']\n",
    "\n",
    "# Drop those features from the DataFrame\n",
    "for feat in feats_to_drop:\n",
    "    if feat in df.columns:\n",
    "        df.drop(columns=feat, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to process numerical and categorical variables differently, but right now some categorical variables are still showing up as numeric because NaNs haven't been filled in with 'missing' (this will be done as part of preprocessing pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df = check_null(df)\n",
    "miss_val_cols = list(null_df.loc[null_df['% Null']>0].index)\n",
    "miss_val_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all columns that are currently object dtype\n",
    "obj_cols = list(df.select_dtypes('O').columns)\n",
    "# add to that list the columns with missing values that will become categorical when 'missing' imputed\n",
    " # use set() so no column appears twice in the list since there's some overlap\n",
    "cat_cols = list(set(obj_cols + miss_val_cols))\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the above need to have null values filled with 'missing' so they will all be categorical if they aren't already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to be treated as numeric in pipeline are all the remaining cols in X \n",
    "# that are not in cat_cols\n",
    "num_cols = [col for col in df.drop('seasonal_vaccine', axis=1).columns if col not in cat_cols]\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target variable\n",
    "target = 'seasonal_vaccine'\n",
    "\n",
    "# separate of features (X) and target (y) for train-test-split\n",
    "X = df.drop(columns=target, axis=1).copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "# define random seed to use for train test split and later for classifiers for reproducibility\n",
    "random_seed = 319\n",
    "\n",
    "## split the data into training and test sets prior to preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=random_seed)\n",
    "\n",
    "# check for class imbalance across all sets of y\n",
    "print('**original**\\n', y.value_counts(normalize=True), '\\n------\\n')\n",
    "print('**y_train**\\n', y_train.value_counts(normalize=True), '\\n------\\n')\n",
    "print('**y_test**\\n', y_test.value_counts(normalize=True), '\\n------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute and scale numerical features\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "X_train_num = num_imputer.fit_transform(X_train[num_cols])\n",
    "X_test_num = num_imputer.transform(X_test[num_cols])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train_num)\n",
    "X_test_num_scaled = scaler.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute and encode categorical features\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "X_train_cat = cat_imputer.fit_transform(X_train[cat_cols])\n",
    "X_test_cat = cat_imputer.transform(X_test[cat_cols])\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='error', sparse=False, drop='if_binary')\n",
    "X_train_cat_encoded = encoder.fit_transform(X_train_cat)\n",
    "X_test_cat_encoded = encoder.transform(X_test_cat)\n",
    "\n",
    "# Combine transformed numerical and categorical data\n",
    "X_train_combined = np.concatenate((X_train_num, X_train_cat_encoded), axis=1)\n",
    "X_test_combined = np.concatenate((X_test_num, X_test_cat_encoded), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "num_feature_names = num_cols\n",
    "cat_feature_names = encoder.get_feature_names_out(input_features=cat_cols)\n",
    "feature_names = np.concatenate((num_feature_names, cat_feature_names))\n",
    "\n",
    "print(feature_names)\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessed DataFrames\n",
    "preprocessed_train_df = pd.DataFrame(X_train_combined, columns=feature_names)\n",
    "preprocessed_test_df = pd.DataFrame(X_test_combined, columns=feature_names)\n",
    "\n",
    "# Display preprocessed DataFrames\n",
    "print(preprocessed_train_df)\n",
    "print(preprocessed_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_df.info()\n",
    "preprocessed_test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a Logistic Regression model\n",
    "logreg = LogisticRegression(random_state=random_seed,C = 0.1)\n",
    "\n",
    "# Fit the logistic regression model using the encoded data\n",
    "logreg.fit(preprocessed_train_df, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg.predict(preprocessed_test_df)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "y_prob = logreg.predict_proba(preprocessed_test_df)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_title = 'Logistic Regression feature importances'\n",
    "def plot_feat_importance (logreg, feature_names, ):\n",
    "  \"\"\"Plots the feature importances of a LogisticRegression model using Seaborn.\"\"\"\n",
    "\n",
    "  # Retrieve feature importances from the model\n",
    "  feature_importances = logreg.coef_[0]\n",
    "  model_title = 'Logistic Regression feature importances'\n",
    "  # Create a pandas Series to hold feature importances with feature names as index\n",
    "  importance = pd.Series(feature_importances, index=feature_names)\n",
    "\n",
    "  # Plot the feature importances using Seaborn\n",
    "  plt.figure(figsize=(12,10))\n",
    "  fig = importance.sort_values().tail(5).plot(kind='barh')\n",
    "  fig.set_title('{} Feature Importances'.format(model_title), fontsize=18, fontweight='bold')\n",
    "  plt.xticks(fontsize=12, fontweight='bold')\n",
    "  plt.yticks(fontsize=12)\n",
    "  plt.show()\n",
    "\n",
    "plot_feat_importance(logreg, feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The above graph shows the importance of various logistics regression features in our study. The graph shows that the top 20 most important features for predicting whether a person will get vaccinated for seasonal flu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = logreg.coef_\n",
    "intercept = logreg.intercept_\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"Intercept:\", intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model appears to have reasonably balanced performance, with accuracy, precision, recall, and F1-score in the range of 0.75 to 0.77. The confusion matrix and ROC curve visuals would also provide additional insights into the model's performance, especially regarding false positives and true positives at different threshold levels. The ROC curve and AUC (Area Under the Curve) value give a better understanding of the trade-off between true positive rate and false positive rate for different thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=random_seed)\n",
    "# Fit the classifier on the preprocessed training data\n",
    "dt.fit(preprocessed_train_df, y_train)\n",
    "\n",
    "y_pred_selected = dt.predict(preprocessed_test_df)\n",
    "\n",
    "# model evaluation\n",
    "result = classification_report(y_test, y_pred_selected)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision tree\n",
    "plt.figure(figsize=(10, 6))\n",
    "tree.plot_tree(dt,\n",
    "               feature_names= feature_names.tolist(),\n",
    "               class_names=np.array([\"0\", \"1\", \"seasonal_vaccine_balanced\"]).tolist(),\n",
    "               filled=True)\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_selected)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, dt.predict_proba(preprocessed_test_df)[:, 1])\n",
    "roc_auc = roc_auc_score(y_test, dt.predict_proba(preprocessed_test_df)[:, 1])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'.format(roc_auc))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feat_importance(clf, feature_names, model_title=''):\n",
    "\n",
    "    \"\"\"Takes in an sklearn classifier already fit to training data, the feature names, and optionally a title describing the model. \n",
    "       Returns a horizontal barplot showing the top 20 most important features in descending order.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    feature_importances = clf.feature_importances_\n",
    "\n",
    "    sorted_idx = feature_importances.argsort()\n",
    "\n",
    "    importance = pd.Series(feature_importances, index=feature_names)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    fig = importance.sort_values().tail(5).plot(kind='barh')\n",
    "    fig.set_title('{} Feature Importances'.format(model_title), fontsize=18, fontweight='bold')\n",
    "    plt.xticks(fontsize=12, fontweight='bold')\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "# Plot the feature importances\n",
    "plot_feat_importance(dt, feature_names=preprocessed_train_df.columns, model_title='Decision Tree')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1Tree Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DecisionTreeClassifier with cost complexity pruning\n",
    "clf_pruned = DecisionTreeClassifier(ccp_alpha=0.01, random_state=random_seed)\n",
    "clf_pruned.fit(preprocessed_train_df, y_train)\n",
    "y_pred_pruned = clf_pruned.predict(preprocessed_test_df)\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_pred_pruned)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Plot the pruned tree (optional)\n",
    "plot_tree(clf_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feat_importance(clf_pruned, feature_names=preprocessed_train_df.columns, model_title='Pruned Tree')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Define a grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Perform a grid search with cross-validation\n",
    "grid_search = GridSearchCV(knn_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(preprocessed_train_df, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Use the best model for predictions\n",
    "best_knn = grid_search.best_estimator_\n",
    "y_pred_knn = best_knn.predict(preprocessed_test_df)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_knn)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate ROC curve and AUC for the best KNN model\n",
    "y_prob_knn = best_knn.predict_proba(preprocessed_test_df)[:, 1]\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, y_prob_knn)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "# Plot ROC curve for the best KNN model\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_knn, tpr_knn, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_knn)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) for KNN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Fit the classifier on the preprocessed training data\n",
    "nb_classifier.fit(preprocessed_train_df, y_train)\n",
    "\n",
    "# Predict on the preprocessed test data\n",
    "y_pred_nb = nb_classifier.predict(preprocessed_test_df)\n",
    "\n",
    "# Calculate predicted probabilities for ROC curve\n",
    "y_probs_nb = nb_classifier.predict_proba(preprocessed_test_df)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs_nb)\n",
    "roc_auc = roc_auc_score(y_test, y_probs_nb)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    " # Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=nb_classifier.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes classifier demonstrated a balanced performance on the test dataset. It exhibited relatively good precision for classifying individuals who did not get vaccinated (0.81) and satisfactory precision for those who did (0.67). It effectively identified a significant proportion of vaccinated individuals (recall of 0.82) while maintaining reasonable recall for non-vaccinated individuals (0.65). The F1-scores for both classes were comparable (0.72 for non-vaccinated and 0.74 for vaccinated), indicating a harmonious trade-off between precision and recall. The model achieved an overall accuracy of 73%, effectively predicting the vaccination status for the majority of instances. The macro and weighted averages suggest consistent performance across the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.1Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=random_seed)\n",
    "\n",
    "# Fit the model on the preprocessed training data\n",
    "rf_classifier.fit(preprocessed_train_df, y_train)\n",
    "\n",
    "# Predict on the preprocessed test data\n",
    "y_pred_rf = rf_classifier.predict(preprocessed_test_df)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "y_prob_rf = rf_classifier.predict_proba(preprocessed_test_df)[:, 1]\n",
    "roc_auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob_rf)\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_rf)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feat_importance(rf_classifier, feature_names=preprocessed_train_df.columns, model_title='Random Forest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report indicates that the Random Forest classifier achieves a 77% overall accuracy in predicting vaccine acceptance. The model demonstrates balanced precision and recall values for both vaccine acceptance and non-acceptance, with precision around 76-78% and recall around 74-79%. This suggests consistent accuracy in identifying both outcomes. The F1-scores, combining precision and recall, range from 0.75 to 0.78 for both classes. In summary, the Random Forest model shows a balanced and satisfactory performance in predicting vaccine acceptance, with potential for informing public health decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on categorical variables with drop=\"first\"\n",
    "preprocessed_train_df_encoded = pd.get_dummies(preprocessed_train_df, drop_first=True)\n",
    "preprocessed_test_df_encoded = pd.get_dummies(preprocessed_test_df, drop_first=True)\n",
    "\n",
    "# Ensure both encoded DataFrames have the same columns\n",
    "common_columns = set(preprocessed_train_df_encoded.columns) & set(preprocessed_test_df_encoded.columns)\n",
    "preprocessed_train_df_encoded = preprocessed_train_df_encoded[common_columns]\n",
    "preprocessed_test_df_encoded = preprocessed_test_df_encoded[common_columns]\n",
    "\n",
    "# Convert feature names to strings \n",
    "clean_feature_names = [str(col).replace('[', '').replace(']', '').replace('<', '') for col in preprocessed_train_df_encoded.columns]\n",
    "\n",
    "# Assign clean feature names to the encoded DataFrames\n",
    "preprocessed_train_df_encoded.columns = clean_feature_names\n",
    "preprocessed_test_df_encoded.columns = clean_feature_names\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier(random_state=random_seed)\n",
    "\n",
    "# Fit the classifier on the preprocessed training data\n",
    "xgb_classifier.fit(preprocessed_train_df_encoded, y_train)\n",
    "\n",
    "# Predict on the preprocessed test data\n",
    "y_pred_xgb = xgb_classifier.predict(preprocessed_test_df_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feat_importance(rf_classifier, feature_names=preprocessed_train_df.columns, model_title='XG BOOST')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost model shows balanced performance in terms of precision, recall, and F1-score for both classes. The model is slightly better at identifying the \"Not Vaccinated\" class, as indicated by the higher precision and recall for that class. The overall accuracy of 77% suggests that the model is performing reasonably well in predicting whether an individual has been vaccinated or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_count_by_grp(group, data, hue='seasonal_vaccine',\n",
    "                      labels=['No Vacc', 'Vaccine'], title='',\n",
    "                      y_label='# of Respondents', x_label='',\n",
    "                      x_tick_labels=False, rotate=True,\n",
    "                      grp_order=None):\n",
    "    \n",
    "    font_dict = {}\n",
    "    font_dict['title'] = {'fontsize':18, 'fontweight':'bold'}\n",
    "    font_dict['axis_label'] = {'fontsize':14, 'fontweight':'bold'}\n",
    "    font_dict['ticks'] = {'size':14}\n",
    "    font_dict['legend'] = {'fontsize':12}\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    fig = sns.countplot(x=group, hue=hue,\n",
    "                  data=data, palette='nipy_spectral',\n",
    "                      order=grp_order)\n",
    "    fig.set_title('Vaccination By {}'.format(title), fontdict=font_dict['title'])\n",
    "    fig.set_xlabel(x_label, fontdict=font_dict['axis_label'])\n",
    "    fig.set_ylabel(y_label, fontdict=font_dict['axis_label'])\n",
    "    fig.tick_params(labelsize=font_dict['ticks']['size'])\n",
    "    \n",
    "    if rotate:\n",
    "        fig.set_xticklabels(fig.get_xticklabels(), rotation=45)\n",
    "    if x_tick_labels:\n",
    "        fig.set_xticklabels(x_tick_labels)\n",
    "\n",
    "    fig.legend(labels=labels, fontsize=font_dict['legend']['fontsize'])\n",
    "    plt.show();\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create df with remaining null values filled in with 'missing' for vizualizations\n",
    "df_missing = df.fillna(value='missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_by_grp(group='opinion_seas_vacc_effective', data=df,\n",
    "                  title='Opinion of Effectiveness',\n",
    "                  x_label='Rating');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As expected, higher vaccination rates are associated with a strong belief in the vaccine's effectiveness. While most individuals consider the flu vaccine to be moderately effective (rated as 4 - Somewhat Effective), they still tend to be less inclined to receive the vaccine. Conversely, those who rate the vaccine as highly effective (rated as 5 - Very Effective) are more likely to have been vaccinated. This underscores the significance of presenting compelling evidence and engaging in effective communication with the public regarding the vaccine's ability to provide substantial protection against the flu virus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_by_grp(group='doctor_recc_seasonal', data=df_missing,\n",
    "                  title='Doctor Recommendation',\n",
    "                  x_tick_labels=['Did Not Rec', 'No Answer', 'Recommended']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The primary influential factor in predicting vaccination behavior is receiving a recommendation for the flu vaccine from a doctor. Individuals who were advised by their physician to get vaccinated showed a significantly higher likelihood of having received the vaccine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_by_grp(group='doctor_recc_seasonal', data=df_missing,\n",
    "                  title='Doctor Recommendation',\n",
    "                  x_tick_labels=['Did Not Rec', 'No Answer', 'Recommended']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary influential factor in predicting vaccination behavior is receiving a recommendation for the flu vaccine from a doctor. Individuals who were advised by their physician to get vaccinated showed a significantly higher likelihood of having received the vaccine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_by_grp(group='opinion_seas_risk', data=df,\n",
    "                  title='Opinion of Risk without Vaccine',\n",
    "                  x_label='Rating');    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, individuals who harbor greater concerns about falling ill without vaccination are more inclined to receive the vaccine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_by_grp(group='age_group', data=df,\n",
    "                  title='Age Group',\n",
    "                  x_label='Age Group',\n",
    "                  grp_order=['18 - 34 Years', '35 - 44 Years', '45 - 54 Years',\n",
    "                             '55 - 64 Years', '65+ Years']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Among the top five influential factors, two distinct age groups stand out:\n",
    "  - **65+ Years**: Individuals in this age bracket exhibit a significantly higher inclination to receive the flu vaccine. This is a positive indicator, given their heightened vulnerability to flu-related complications. It is plausible that healthcare professionals prioritize recommending the vaccine to this group.\n",
    "  - **18 - 34 Years**: Within this age range, a notable proportion of individuals opt against vaccination compared to those who choose to be vaccinated. While this demographic faces a relatively lower risk of flu-related complications, targeting and promoting vaccination within this group would be essential to enhance overall population-level immunity.\n",
    "- Broadly, there is an observable trend of increasing vaccination rates with advancing age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_by_grp(group='education', data=df,\n",
    "                  title='Level of Education',\n",
    "                  x_label='Education',\n",
    "                  grp_order=['< 12 Years', '12 Years', 'Some College', 'College Graduate'],\n",
    "                  x_tick_labels=['< 12 Years', '12 Years', 'Some College', 'College Grad']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As education levels rise, the percentage of vaccinated individuals within each category also increases. This contrast is particularly pronounced for individuals who did not attain a high school diploma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_by_grp(group='income_poverty', data=df_missing,\n",
    "                  title='Income',\n",
    "                  x_label='Income',\n",
    "                  x_tick_labels=['Below Poverty', 'Above Poverty', '> $75,000', 'No Answer']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Individuals residing in households with incomes below the 2008 Census poverty threshold exhibit lower vaccine uptake. In contrast, the distribution of vaccinated and non-vaccinated individuals is more equitable across the remaining income categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_by_grp(group='race', data=df,\n",
    "                  title='Race',\n",
    "                  x_label='Race');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While white respondents displayed a roughly equal likelihood of receiving or not receiving the vaccine, people of color (POC) showed a notably lower tendency to get vaccinated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top-performing classifier is XGB classifier prioritizes accuracy, highlights that the three most significant factors influencing the decision of individuals to receive the seasonal flu vaccine in 2009 were as follows:\n",
    "- Doctor recommendations - Seasonal flu vaccine was recommended by doctor\n",
    "- Perceived Risk of Contracting Flu without the Vaccine\n",
    "- Respondent's opinion about seasonal flu vaccine effectiveness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To enhance the uptake of seasonal flu vaccination, the following strategies could be considered by the government:\n",
    "\n",
    " - **Enhance Public Awareness Regarding Vaccine Effectiveness**: Efforts should focus on increasing public knowledge about the vaccine's effectiveness in safeguarding against the flu. These awareness initiatives could be executed at the community or national level. Disseminating credible evidence through channels like television or online advertisements can facilitate informed decision-making. Simultaneously, there's an opportunity to underscore the vaccine's safety, which is a pivotal factor in predicting vaccination status. This can be especially crucial when contrasting the vaccine's safety with the potential risks of contracting the seasonal flu.\n",
    "\n",
    "\n",
    "- **Encourage Regular Physician Recommendations**: To bolster herd immunity, it is advisable for healthcare providers to consistently advise their patients to undergo seasonal flu vaccination annually. This personalized approach may yield better results compared to generalized vaccine promotion through alternative means. Nonetheless, comprehensive campaigns remain vital for reaching individuals who may not have routine access to healthcare services.\n",
    "\n",
    "To elevate the overall vaccination rate against seasonal flu, initiatives should prioritize encouraging, educating, and ensuring healthcare access for the following demographics:\n",
    "\n",
    "- Individuals aged 18 to 34\n",
    "- Uninsured individuals\n",
    "- Renters\n",
    "- Communities of color\n",
    "- Those with income below the poverty threshold\n",
    "- Individuals without a high school diploma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
